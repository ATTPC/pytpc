#!/usr/bin/env python3
"""pyclean
Authors M.P. Kuchera, J. Bradt

This python script parses through a data file and removes noise

This code:
1) Does a nearest neighbor comparison to eliminate statistical noise
2) Does a circular Hough transform to find the center of the spiral or curved track in the micromegas pad plane
3) Does a linear Hough transform on (z,r*phi) to find which points lie along the spiral/curve
4) Writes points and their distance from the line to an HDF5 file

This distance can be used to make cuts on how agressively you want to clean the data.
"""

import argparse
import pytpc
from pytpc.cleaning import EventCleaner
import sys
import h5py
import yaml
import logging
import logging.config

logger = logging.getLogger(__name__)


def event_iterator(input_evtid_set, output_evtid_set):
    """Iterates through event IDs that need to be processed.

    This takes two sets: a set of IDs that are in the input file, and a set of IDs that are in the output file.
    It then yields event IDs that are in the first, but not the second.

    Parameters
    ----------
    input_evtid_set : set
        A set of integer event IDs that are present in the input file.
    output_evtid_set : set
        A set of integer event IDs that are present in the output file.

    Yields
    ------
    int
        The next event ID to process.

    """
    unprocessed_events = input_evtid_set - output_evtid_set
    num_input_evts = len(input_evtid_set)
    num_events_remaining = len(unprocessed_events)
    num_events_finished = len(output_evtid_set)
    if num_events_remaining == 0:
        logger.warning('All events have already been processed.')
        raise StopIteration()
    elif num_events_finished > 0:
        logger.info('Already processed %d events. Continuing from where we left off.', num_events_finished)

    for i in unprocessed_events:
        if i % 100 == 0:
            logger.info('Processed %d / %d events', i, num_input_evts)
        yield i
    else:
        raise StopIteration()


def setup_logging(config):
    """Configures the logging library based on the parameters in the config file."""
    try:
        log_conf = config['logging_config']
        logging.config.dictConfig(log_conf)
    except KeyError:
        logger.exception('Log config failed')


def main():
    parser = argparse.ArgumentParser(description='A script to clean data and write results to an HDF5 file')
    parser.add_argument('--canon-evtids', help='Path to HDF5 file containing canonical evt ids')
    parser.add_argument('config', help='Path to a config file')
    parser.add_argument('input', help='The input evt file')
    parser.add_argument('output', help='The output HDF5 file')
    args = parser.parse_args()

    with open(args.config) as f:
        config = yaml.load(f)

    setup_logging(config)

    inFile = pytpc.HDFDataFile(args.input, 'r', canonical_evtid_path=args.canon_evtids)

    cleaner = EventCleaner(config)

    with h5py.File(args.output, 'a') as outFile:
        gp = outFile.require_group('clean')  # This HDF5 group will contain the cleaned data

        logger.info('Finding set of event IDs in input')
        input_evtid_set = {k for k in inFile.evtids()}
        num_input_evts = len(input_evtid_set)
        logger.info('Input file contains %d events', num_input_evts)

        output_evtid_set = {int(k) for k in gp}

        for evt_index in event_iterator(input_evtid_set, output_evtid_set):
            # Read the data from the input file
            try:
                evt = inFile[evt_index]
            except Exception:
                logger.exception('Failed to read event with index %d from input', evt_index)
                continue

            # Clean the data
            try:
                clean_xyz, center = cleaner.process_event(evt)
            except Exception:
                logger.exception('Cleaning failed for event with index %d', evt_index)
                continue

            # Write the cleaned data to the output file
            try:
                dset = gp.create_dataset('{:d}'.format(evt.evt_id), data=clean_xyz, compression='gzip', shuffle=True)
                dset.attrs['center'] = center
            except Exception:
                logger.exception('Writing to HDF5 failed for event with index %d', evt_index)
                continue


if __name__ == '__main__':
    import signal

    def handle_signal(signum, stack_frame):
        """Gracefully exit when receiving the given signal."""
        logger.critical('Received signal %d. Quitting.', signum)
        sys.stdout.flush()
        sys.exit(1)

    # Handle SIGTERM and SIGQUIT so the HDF5 file will be closed safely if the HPCC kills this program
    signal.signal(signal.SIGTERM, handle_signal)
    signal.signal(signal.SIGQUIT, handle_signal)

    main()
