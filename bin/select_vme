#!/usr/bin/env python3
"""
select_vme

A script to select good events from the unpacked VME data (see unpack_vme).

This will select events from the VME data that satisfy the following requirements:

- Coincidence between at least one CoBo and the ion chamber.
- Event does not saturate the ion chamber ADC
- Event has a recorded trigger signal
- Event has *one* peak in the ion chamber

The output is an HDF5 file containing one dataset, 'single_ic_pk_heights', which can be
read using Pandas' `pd.read_hdf` function. This contains the peak maximum time ('pk_pos') and height ('height'), and
the time of the peak as determined by a constant fraction discrimination filter ('cfd_pos').
"""

import numpy as np
import pandas as pd
import h5py
from scipy.signal import argrelextrema
import argparse
import yaml
from pytpc.vmedata import VMEAlignmentTable

import logging
import logging.config
logger = logging.getLogger(__name__)


def find_peaks(sig, noise_threshold):
    """Find the position of the maxima all peaks in the signal.

    Parameters
    ----------
    sig : array-like
        The ion chamber signal. This should be inverted (so the peaks are maxima),
        and its baseline should already be subtracted out.
    noise_threshold : number
        A threshold which is used to mask away noise. This prevents the function from
        finding peaks that are just noise.

    Returns
    -------
    pks : np.array
        A list of the positions of the peaks
    """
    mkd = np.ma.masked_less(sig, noise_threshold).filled(np.nan)

    pks = argrelextrema(mkd, comparator=np.greater_equal, order=5, mode='clip')[0]
    adj = pks[np.where(np.diff(pks) == 1)]
    if len(adj) > 0:
        # Handle flat-top peaks.
        adj_chunks = [np.append(a, a.max() + 1) for a in np.split(adj, np.where(np.diff(adj) > 1)[0] + 1)]
        broad_pks = np.round(np.array([a.mean() for a in adj_chunks]))
        narrow_pks = np.setdiff1d(pks, np.concatenate(adj_chunks))
        pks = np.concatenate((broad_pks, narrow_pks))

    return pks


def cfd_trigger(sig, delay, frac, noise_thresh):
    """Find the peak position using a constant fraction discriminator.

    Parameters
    ----------
    sig : np.array
        The ion chamber signal. This should be inverted (so the peaks are maxima),
        and its baseline should already be subtracted out.
    delay : int
        The delay for the CFD.
    frac : float
        The fraction for the CFD.
    noise_thresh : number
        The threshold below which a peak will be considered noise.

    Returns
    -------
    np.array
        The position of the peaks, as determined by the CFD.
    """
    cfd = sig - frac * np.roll(sig, delay)
    # When finding the zero crossings, omit actual zeros since they will otherwise be
    # counted twice because of the way np.sign works.
    zero_crossings = np.logical_and(np.diff(np.sign(cfd)) != 0, cfd[:-1] != 0)
    return np.logical_and(zero_crossings, np.abs(sig[:-1]) > noise_thresh).nonzero()[0] + 1


def coincidence_cut(coinc):
    """Find events that trigger at least one CoBo.
    """
    return np.any(coinc[:, :10], axis=1)


def saturation_cut(ic):
    """Find events that do not saturate the ion chamber.
    """
    return ic.min(axis=1) > 0


def trigger_cut(trig):
    """Find events that have a valid trigger signal.
    """
    return np.any(trig < 250, axis=1)


def perform_cut(dataset, cut_function):
    """Apply the given cut to a dataset.
    
    Parameters
    ----------
    dataset : h5py.Dataset
        The dataset from the HDF5 file.
    cut_function : callable
        A function that returns a Boolean mask of events that pass the cut.
    
    """
    data = dataset[:]
    logger.info('Performing cut with function %s', cut_function.__name__)
    cut = cut_function(data)
    logger.info('%d events were cut', np.where(~cut)[0].shape[0])
    return cut


def select_events(ic, goodidx):
    """Select events that have one peak in the ion chamber.

    Parameters
    ----------
    ic : np.array
        The raw ion chamber signal from the unpacked VME file.
    goodidx : np.array
        The (integer) event IDs of events that should be considered. This could be the set of
        events that pass the other criteria in this script.

    Returns
    -------
    pd.DataFrame
        The height, peak position, and CFD peak position of all events with one ion chamber peak.
    """
    pkdata = []
    dropped_evts_maxes = 0
    dropped_evts_cfd = 0

    for i, evtid in enumerate(goodidx):
        if i % 1000 == 0:
            logger.info('At event %d / %d', i, len(goodidx))

        sig = ic[evtid].astype('float64')  # Required to prevent integer wraparound
        sig = -sig + np.median(sig)  # Remove baseline and invert signal

        pks = find_peaks(sig, 600)
        if len(pks) != 1:
            dropped_evts_maxes += 1
            continue

        cfd_zeros = cfd_trigger(sig, -10, 0.4, 500)
        if len(cfd_zeros) != 1:
            logger.warning('Evt %d: CFD found %d peaks instead of 1. Dropping event.', evtid, len(cfd_zeros))
            dropped_evts_cfd += 1
            continue

        pkdata.append({
            'vme_evt_id': evtid,
            'height': sig[int(pks[0])],
            'pk_pos': pks[0],
            'cfd_pos': cfd_zeros[0]
        })

    logger.info('Dropped %d events that had more than one peak', dropped_evts_maxes)
    logger.warning('Dropped %d events due to bad CFD filter', dropped_evts_cfd)
    return pd.DataFrame(pkdata)


def setup_logging(config):
    """Configure the logging library from the given dictionary.

    The dictionary must have a key "logging_config" that contains a valid configuration for the logging library.

    """
    try:
        log_conf = config['logging_config']
        logging.config.dictConfig(log_conf)
    except KeyError:
        logger.warning('No logging config found. Info messages may be suppressed.')


def parse_arguments():
    parser = argparse.ArgumentParser(description='A script to select good events based on VME data.')
    parser.add_argument('--offsets', '-o', help='Path to HDF5 file containing DAQ alignment offsets.')
    parser.add_argument('config', help='Path to the analysis config file')
    parser.add_argument('vme_data', help='Path to an HDF5 file containing the VME data')
    parser.add_argument('outpath', help='Path to an HDF5 file to write')
    return parser.parse_args()


def fix_offsets(offsets_path, goodvme):
    """Apply DAQ alignment offsets to data.
    
    This produces an extra column of GET event IDs in the dataset.
    
    Parameters
    ----------
    offsets_path : str
        Path to the DAQ alignment offsets file.
    goodvme : pd.DataFrame
        The peak data, as calculated by this script.

    Returns
    -------
    goodvme : pd.DataFrame
        The modified peak data.

    """
    try:
        align_table = VMEAlignmentTable.from_hdf(offsets_path)
    except OSError:
        logger.exception('Invalid path given for offsets table. Event IDs were not corrected.')
    else:
        goodvme['get_evt_id'] = [align_table.vme_to_get(e) for e in goodvme['vme_evt_id']]

    return goodvme


def main():
    args = parse_arguments()

    with open(args.config, 'r') as f:
        config = yaml.load(f)

    setup_logging(config)

    with h5py.File(args.vme_data, 'r') as h5file:
        logger.info('Total number of events is %d', len(h5file['/vme/coinc']))

        coinccut = perform_cut(h5file['/vme/coinc'], coincidence_cut)
        trigcut = perform_cut(h5file['/vme/trig'], trigger_cut)
        satcut = perform_cut(h5file['/vme/ic'], saturation_cut)

        total_cut = np.all(np.column_stack((coinccut, trigcut, satcut)), axis=1)
        cut_idx = np.where(total_cut)[0]
        logger.info('After cuts, %d good events remain (%d were cut)',
                    cut_idx.shape[0], np.where(~total_cut)[0].shape[0])

        logger.info('Finding single peaks for remaining events')
        goodvme = select_events(h5file['/vme/ic'][:], cut_idx)
        logger.info('Finished processing. Found %d single peaks.', len(goodvme))

    if args.offsets is not None:
        logger.info('Applying DAQ alignment offsets.')
        goodvme = fix_offsets(args.offsets, goodvme)

    goodvme.to_hdf(args.outpath, 'single_ic_pk_heights', format='t')


if __name__ == '__main__':
    import signal
    import sys

    def handle_signal(signum, stack_frame):
        logger.critical('Received signal %d. Quitting.', signum)
        sys.stdout.flush()
        sys.exit(1)

    signal.signal(signal.SIGTERM, handle_signal)
    signal.signal(signal.SIGQUIT, handle_signal)

    main()
